nohup: ignoring input
2025-05-30 15:32:12.255724: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-30 15:32:12.595756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-30 15:32:17.892018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46542 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:3d:00.0, compute capability: 8.9
2025-05-30 15:32:17.893773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46551 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9
Number of devices: 2
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 35, 35, 3)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 35, 35, 64)           4864      ['input_1[0][0]']             
                                                                                                  
 conv2d_2 (Conv2D)           (None, 35, 35, 64)           4160      ['conv2d[0][0]']              
                                                                                                  
 conv2d_4 (Conv2D)           (None, 35, 35, 64)           4160      ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 35, 35, 64)           0         ['conv2d[0][0]']              
 D)                                                                                               
                                                                                                  
 conv2d_1 (Conv2D)           (None, 35, 35, 64)           4160      ['conv2d[0][0]']              
                                                                                                  
 conv2d_3 (Conv2D)           (None, 35, 35, 64)           36928     ['conv2d_2[0][0]']            
                                                                                                  
 conv2d_5 (Conv2D)           (None, 35, 35, 64)           102464    ['conv2d_4[0][0]']            
                                                                                                  
 conv2d_6 (Conv2D)           (None, 35, 35, 64)           4160      ['max_pooling2d[0][0]']       
                                                                                                  
 concatenate (Concatenate)   (None, 35, 35, 256)          0         ['conv2d_1[0][0]',            
                                                                     'conv2d_3[0][0]',            
                                                                     'conv2d_5[0][0]',            
                                                                     'conv2d_6[0][0]']            
                                                                                                  
 conv2d_7 (Conv2D)           (None, 35, 35, 128)          295040    ['concatenate[0][0]']         
                                                                                                  
 batch_normalization (Batch  (None, 35, 35, 128)          512       ['conv2d_7[0][0]']            
 Normalization)                                                                                   
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 12, 12, 128)          0         ['batch_normalization[0][0]'] 
 g2D)                                                                                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 12, 12, 256)          33024     ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 12, 12, 256)          33024     ['max_pooling2d_1[0][0]']     
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 12, 12, 128)          0         ['max_pooling2d_1[0][0]']     
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 12, 12, 256)          33024     ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_10 (Conv2D)          (None, 12, 12, 256)          590080    ['conv2d_9[0][0]']            
                                                                                                  
 conv2d_12 (Conv2D)          (None, 12, 12, 256)          1638656   ['conv2d_11[0][0]']           
                                                                                                  
 conv2d_13 (Conv2D)          (None, 12, 12, 256)          33024     ['max_pooling2d_2[0][0]']     
                                                                                                  
 concatenate_1 (Concatenate  (None, 12, 12, 1024)         0         ['conv2d_8[0][0]',            
 )                                                                   'conv2d_10[0][0]',           
                                                                     'conv2d_12[0][0]',           
                                                                     'conv2d_13[0][0]']           
                                                                                                  
 conv2d_14 (Conv2D)          (None, 12, 12, 512)          4719104   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_1 (Bat  (None, 12, 12, 512)          2048      ['conv2d_14[0][0]']           
 chNormalization)                                                                                 
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 4, 4, 512)            0         ['batch_normalization_1[0][0]'
 g2D)                                                               ]                             
                                                                                                  
 conv2d_16 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_3[0][0]']     
                                                                                                  
 conv2d_18 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_3[0][0]']     
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 4, 4, 512)            0         ['max_pooling2d_3[0][0]']     
 g2D)                                                                                             
                                                                                                  
 conv2d_15 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_3[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 4, 4, 256)            590080    ['conv2d_16[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 4, 4, 256)            1638656   ['conv2d_18[0][0]']           
                                                                                                  
 conv2d_20 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_4[0][0]']     
                                                                                                  
 concatenate_2 (Concatenate  (None, 4, 4, 1024)           0         ['conv2d_15[0][0]',           
 )                                                                   'conv2d_17[0][0]',           
                                                                     'conv2d_19[0][0]',           
                                                                     'conv2d_20[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 4, 4, 256)            2359552   ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 4, 4, 256)            1024      ['conv2d_21[0][0]']           
 chNormalization)                                                                                 
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 2, 2, 256)            0         ['batch_normalization_2[0][0]'
 g2D)                                                               ]                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_5[0][0]']     
                                                                                                  
 conv2d_25 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_5[0][0]']     
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 2, 2, 256)            0         ['max_pooling2d_5[0][0]']     
 g2D)                                                                                             
                                                                                                  
 conv2d_22 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_5[0][0]']     
                                                                                                  
 conv2d_24 (Conv2D)          (None, 2, 2, 256)            590080    ['conv2d_23[0][0]']           
                                                                                                  
 conv2d_26 (Conv2D)          (None, 2, 2, 256)            1638656   ['conv2d_25[0][0]']           
                                                                                                  
 conv2d_27 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_6[0][0]']     
                                                                                                  
 concatenate_3 (Concatenate  (None, 2, 2, 1024)           0         ['conv2d_22[0][0]',           
 )                                                                   'conv2d_24[0][0]',           
                                                                     'conv2d_26[0][0]',           
                                                                     'conv2d_27[0][0]']           
                                                                                                  
 conv2d_28 (Conv2D)          (None, 2, 2, 512)            4719104   ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_3 (Bat  (None, 2, 2, 512)            2048      ['conv2d_28[0][0]']           
 chNormalization)                                                                                 
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 1, 1, 512)            0         ['batch_normalization_3[0][0]'
 g2D)                                                               ]                             
                                                                                                  
 flatten (Flatten)           (None, 512)                  0         ['max_pooling2d_7[0][0]']     
                                                                                                  
 dense (Dense)               (None, 300)                  153900    ['flatten[0][0]']             
                                                                                                  
 reshape (Reshape)           (None, 10, 10, 3)            0         ['dense[0][0]']               
                                                                                                  
==================================================================================================
Total params: 20020012 (76.37 MB)
Trainable params: 20017196 (76.36 MB)
Non-trainable params: 2816 (11.00 KB)
__________________________________________________________________________________________________
Training set: (392000, 35, 35, 3) (392000, 10, 10, 3)
Validation set: (84000, 35, 35, 3) (84000, 10, 10, 3)
Test set: (84000, 35, 35, 3) (84000, 10, 10, 3)
Epoch 1/35
2025-05-30 15:38:47.109238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907
2025-05-30 15:38:47.126705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907
2025-05-30 15:38:49.348023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2025-05-30 15:38:52.462406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f03f773f020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-05-30 15:38:52.462466: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9
2025-05-30 15:38:52.462476: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9
2025-05-30 15:38:52.587737: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-05-30 15:38:53.249384: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
766/766 - 121s - loss: 262.3638 - val_loss: 248.5550 - 121s/epoch - 157ms/step
Epoch 2/35
766/766 - 72s - loss: 189.1624 - val_loss: 189.6803 - 72s/epoch - 95ms/step
Epoch 3/35
766/766 - 73s - loss: 173.6483 - val_loss: 199.8705 - 73s/epoch - 96ms/step
Epoch 4/35
766/766 - 74s - loss: 166.9808 - val_loss: 192.7137 - 74s/epoch - 96ms/step
Epoch 5/35
766/766 - 74s - loss: 146.5158 - val_loss: 213.0357 - 74s/epoch - 97ms/step
Epoch 6/35
766/766 - 75s - loss: 119.8257 - val_loss: 365.1945 - 75s/epoch - 98ms/step
Epoch 7/35
766/766 - 75s - loss: 105.8164 - val_loss: 137.1732 - 75s/epoch - 97ms/step
Epoch 8/35
766/766 - 75s - loss: 97.8359 - val_loss: 109.4453 - 75s/epoch - 97ms/step
Epoch 9/35
766/766 - 76s - loss: 93.5373 - val_loss: 134.0462 - 76s/epoch - 99ms/step
Epoch 10/35
766/766 - 74s - loss: 89.4925 - val_loss: 241.5378 - 74s/epoch - 96ms/step
Epoch 11/35
766/766 - 74s - loss: 86.6557 - val_loss: 218.5540 - 74s/epoch - 96ms/step
Epoch 12/35
766/766 - 74s - loss: 84.6590 - val_loss: 128.2178 - 74s/epoch - 96ms/step
Epoch 13/35
766/766 - 73s - loss: 81.5380 - val_loss: 115.7670 - 73s/epoch - 96ms/step
Epoch 14/35
766/766 - 75s - loss: 78.8872 - val_loss: 126.8159 - 75s/epoch - 98ms/step
Epoch 15/35
766/766 - 75s - loss: 76.2644 - val_loss: 212.4241 - 75s/epoch - 98ms/step
Epoch 16/35
766/766 - 75s - loss: 73.1026 - val_loss: 100.7935 - 75s/epoch - 98ms/step
Epoch 17/35
766/766 - 74s - loss: 70.6370 - val_loss: 161.4980 - 74s/epoch - 97ms/step
Epoch 18/35
766/766 - 75s - loss: 68.5610 - val_loss: 164.3628 - 75s/epoch - 98ms/step
Epoch 19/35
766/766 - 75s - loss: 65.6047 - val_loss: 321.1742 - 75s/epoch - 98ms/step
Epoch 20/35
766/766 - 75s - loss: 63.1521 - val_loss: 181.8786 - 75s/epoch - 98ms/step
Epoch 21/35
766/766 - 75s - loss: 60.8536 - val_loss: 140.4686 - 75s/epoch - 98ms/step
Epoch 22/35
766/766 - 75s - loss: 58.3278 - val_loss: 128.2378 - 75s/epoch - 97ms/step
Epoch 23/35
766/766 - 76s - loss: 56.5471 - val_loss: 137.6145 - 76s/epoch - 99ms/step
Epoch 24/35
766/766 - 75s - loss: 54.3311 - val_loss: 133.1630 - 75s/epoch - 98ms/step
Epoch 25/35
766/766 - 75s - loss: 52.5569 - val_loss: 98.6374 - 75s/epoch - 98ms/step
Epoch 26/35
766/766 - 75s - loss: 50.6118 - val_loss: 115.7865 - 75s/epoch - 98ms/step
Epoch 27/35
766/766 - 75s - loss: 48.7581 - val_loss: 178.8364 - 75s/epoch - 98ms/step
Epoch 28/35
766/766 - 75s - loss: 46.5803 - val_loss: 126.0788 - 75s/epoch - 98ms/step
Epoch 29/35
766/766 - 76s - loss: 44.9395 - val_loss: 106.4154 - 76s/epoch - 99ms/step
Epoch 30/35
766/766 - 75s - loss: 43.2681 - val_loss: 113.4276 - 75s/epoch - 98ms/step
Epoch 31/35
766/766 - 74s - loss: 41.7266 - val_loss: 104.4717 - 74s/epoch - 97ms/step
Epoch 32/35
766/766 - 74s - loss: 40.4724 - val_loss: 263.7144 - 74s/epoch - 97ms/step
Epoch 33/35
766/766 - 74s - loss: 38.4215 - val_loss: 119.2577 - 74s/epoch - 96ms/step
Epoch 34/35
766/766 - 74s - loss: 37.2544 - val_loss: 247.9784 - 74s/epoch - 96ms/step
Epoch 35/35
766/766 - 74s - loss: 35.9272 - val_loss: 169.8791 - 74s/epoch - 96ms/step
Test Loss (MSE): 169.813812
Model saved to models/incept_surface_3005_1623_35ep_169.8138.keras
History saved to models/history_3005_1623_35ep_169.8138.json
Traceback (most recent call last):
  File "incept_surface_model.py", line 306, in <module>
    main(args.epochs, args.data_path)
TypeError: main() missing 1 required positional argument: 'use_subdiv'
