nohup: ignoring input
2025-06-02 18:34:49.902582: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-06-02 18:34:50.795987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-02 18:34:57.354112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46551 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9
2025-06-02 18:34:57.356243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46542 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:3d:00.0, compute capability: 8.9
Number of devices: 2
Training set: (928000, 35, 35, 3) (928000, 10, 10, 3)
Validation set: (116000, 35, 35, 3) (116000, 10, 10, 3)
Test set: (116000, 35, 35, 3) (116000, 10, 10, 3)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 35, 35, 3)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 35, 35, 64)           4864      ['input_1[0][0]']             
                                                                                                  
 conv2d_2 (Conv2D)           (None, 35, 35, 64)           4160      ['conv2d[0][0]']              
                                                                                                  
 conv2d_4 (Conv2D)           (None, 35, 35, 64)           4160      ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 35, 35, 64)           0         ['conv2d[0][0]']              
 D)                                                                                               
                                                                                                  
 conv2d_1 (Conv2D)           (None, 35, 35, 64)           4160      ['conv2d[0][0]']              
                                                                                                  
 conv2d_3 (Conv2D)           (None, 35, 35, 64)           36928     ['conv2d_2[0][0]']            
                                                                                                  
 conv2d_5 (Conv2D)           (None, 35, 35, 64)           102464    ['conv2d_4[0][0]']            
                                                                                                  
 conv2d_6 (Conv2D)           (None, 35, 35, 64)           4160      ['max_pooling2d[0][0]']       
                                                                                                  
 concatenate (Concatenate)   (None, 35, 35, 256)          0         ['conv2d_1[0][0]',            
                                                                     'conv2d_3[0][0]',            
                                                                     'conv2d_5[0][0]',            
                                                                     'conv2d_6[0][0]']            
                                                                                                  
 dropout (Dropout)           (None, 35, 35, 256)          0         ['concatenate[0][0]']         
                                                                                                  
 conv2d_7 (Conv2D)           (None, 35, 35, 128)          295040    ['dropout[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 35, 35, 128)          512       ['conv2d_7[0][0]']            
 Normalization)                                                                                   
                                                                                                  
 dropout_1 (Dropout)         (None, 35, 35, 128)          0         ['batch_normalization[0][0]'] 
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 12, 12, 128)          0         ['dropout_1[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 12, 12, 256)          33024     ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 12, 12, 256)          33024     ['max_pooling2d_1[0][0]']     
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 12, 12, 128)          0         ['max_pooling2d_1[0][0]']     
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 12, 12, 256)          33024     ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_10 (Conv2D)          (None, 12, 12, 256)          590080    ['conv2d_9[0][0]']            
                                                                                                  
 conv2d_12 (Conv2D)          (None, 12, 12, 256)          1638656   ['conv2d_11[0][0]']           
                                                                                                  
 conv2d_13 (Conv2D)          (None, 12, 12, 256)          33024     ['max_pooling2d_2[0][0]']     
                                                                                                  
 concatenate_1 (Concatenate  (None, 12, 12, 1024)         0         ['conv2d_8[0][0]',            
 )                                                                   'conv2d_10[0][0]',           
                                                                     'conv2d_12[0][0]',           
                                                                     'conv2d_13[0][0]']           
                                                                                                  
 dropout_2 (Dropout)         (None, 12, 12, 1024)         0         ['concatenate_1[0][0]']       
                                                                                                  
 conv2d_14 (Conv2D)          (None, 12, 12, 512)          4719104   ['dropout_2[0][0]']           
                                                                                                  
 batch_normalization_1 (Bat  (None, 12, 12, 512)          2048      ['conv2d_14[0][0]']           
 chNormalization)                                                                                 
                                                                                                  
 dropout_3 (Dropout)         (None, 12, 12, 512)          0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 4, 4, 512)            0         ['dropout_3[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_16 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_3[0][0]']     
                                                                                                  
 conv2d_18 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_3[0][0]']     
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 4, 4, 512)            0         ['max_pooling2d_3[0][0]']     
 g2D)                                                                                             
                                                                                                  
 conv2d_15 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_3[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 4, 4, 256)            590080    ['conv2d_16[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 4, 4, 256)            1638656   ['conv2d_18[0][0]']           
                                                                                                  
 conv2d_20 (Conv2D)          (None, 4, 4, 256)            131328    ['max_pooling2d_4[0][0]']     
                                                                                                  
 concatenate_2 (Concatenate  (None, 4, 4, 1024)           0         ['conv2d_15[0][0]',           
 )                                                                   'conv2d_17[0][0]',           
                                                                     'conv2d_19[0][0]',           
                                                                     'conv2d_20[0][0]']           
                                                                                                  
 dropout_4 (Dropout)         (None, 4, 4, 1024)           0         ['concatenate_2[0][0]']       
                                                                                                  
 conv2d_21 (Conv2D)          (None, 4, 4, 256)            2359552   ['dropout_4[0][0]']           
                                                                                                  
 batch_normalization_2 (Bat  (None, 4, 4, 256)            1024      ['conv2d_21[0][0]']           
 chNormalization)                                                                                 
                                                                                                  
 dropout_5 (Dropout)         (None, 4, 4, 256)            0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 2, 2, 256)            0         ['dropout_5[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_5[0][0]']     
                                                                                                  
 conv2d_25 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_5[0][0]']     
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 2, 2, 256)            0         ['max_pooling2d_5[0][0]']     
 g2D)                                                                                             
                                                                                                  
 conv2d_22 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_5[0][0]']     
                                                                                                  
 conv2d_24 (Conv2D)          (None, 2, 2, 256)            590080    ['conv2d_23[0][0]']           
                                                                                                  
 conv2d_26 (Conv2D)          (None, 2, 2, 256)            1638656   ['conv2d_25[0][0]']           
                                                                                                  
 conv2d_27 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_6[0][0]']     
                                                                                                  
 concatenate_3 (Concatenate  (None, 2, 2, 1024)           0         ['conv2d_22[0][0]',           
 )                                                                   'conv2d_24[0][0]',           
                                                                     'conv2d_26[0][0]',           
                                                                     'conv2d_27[0][0]']           
                                                                                                  
 dropout_6 (Dropout)         (None, 2, 2, 1024)           0         ['concatenate_3[0][0]']       
                                                                                                  
 conv2d_28 (Conv2D)          (None, 2, 2, 512)            4719104   ['dropout_6[0][0]']           
                                                                                                  
 batch_normalization_3 (Bat  (None, 2, 2, 512)            2048      ['conv2d_28[0][0]']           
 chNormalization)                                                                                 
                                                                                                  
 dropout_7 (Dropout)         (None, 2, 2, 512)            0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 1, 1, 512)            0         ['dropout_7[0][0]']           
 g2D)                                                                                             
                                                                                                  
 flatten (Flatten)           (None, 512)                  0         ['max_pooling2d_7[0][0]']     
                                                                                                  
 dropout_8 (Dropout)         (None, 512)                  0         ['flatten[0][0]']             
                                                                                                  
 dense (Dense)               (None, 300)                  153900    ['dropout_8[0][0]']           
                                                                                                  
 reshape (Reshape)           (None, 10, 10, 3)            0         ['dense[0][0]']               
                                                                                                  
==================================================================================================
Total params: 20020012 (76.37 MB)
Trainable params: 20017196 (76.36 MB)
Non-trainable params: 2816 (11.00 KB)
__________________________________________________________________________________________________
Epoch 1/130
2025-06-02 19:13:31.745133: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
2025-06-02 19:13:35.895661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907
2025-06-02 19:13:35.897718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907
2025-06-02 19:13:37.599664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2025-06-02 19:13:43.459004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0b0d613ae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-06-02 19:13:43.461462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9
2025-06-02 19:13:43.461479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9
2025-06-02 19:13:43.836501: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-06-02 19:13:45.417493: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1813/1813 - 303s - loss: 336.2733 - mse: 258.7156 - val_loss: 343.0371 - val_mse: 271.3425 - 303s/epoch - 167ms/step
Epoch 2/130
1813/1813 - 211s - loss: 260.0439 - mse: 197.5183 - val_loss: 300.0447 - val_mse: 236.9807 - 211s/epoch - 117ms/step
Epoch 3/130
1813/1813 - 210s - loss: 244.4452 - mse: 185.7430 - val_loss: 301.6532 - val_mse: 240.0601 - 210s/epoch - 116ms/step
Epoch 4/130
1813/1813 - 210s - loss: 222.4027 - mse: 165.1743 - val_loss: 285.3859 - val_mse: 223.8891 - 210s/epoch - 116ms/step
Epoch 5/130
1813/1813 - 210s - loss: 196.4008 - mse: 140.8032 - val_loss: 259.0988 - val_mse: 199.8047 - 210s/epoch - 116ms/step
Epoch 6/130
1813/1813 - 210s - loss: 176.4788 - mse: 122.6673 - val_loss: 232.1896 - val_mse: 175.6877 - 210s/epoch - 116ms/step
Epoch 7/130
1813/1813 - 208s - loss: 159.3165 - mse: 107.7325 - val_loss: 227.5954 - val_mse: 172.4322 - 208s/epoch - 115ms/step
Epoch 8/130
1813/1813 - 209s - loss: 147.3008 - mse: 98.0748 - val_loss: 211.0201 - val_mse: 157.2771 - 209s/epoch - 115ms/step
Epoch 9/130
1813/1813 - 211s - loss: 138.7713 - mse: 91.8774 - val_loss: 217.0093 - val_mse: 162.7537 - 211s/epoch - 117ms/step
Epoch 10/130
1813/1813 - 209s - loss: 132.8220 - mse: 87.6687 - val_loss: 240.0772 - val_mse: 184.0780 - 209s/epoch - 115ms/step
Epoch 11/130
1813/1813 - 208s - loss: 128.1391 - mse: 84.4333 - val_loss: 234.0408 - val_mse: 178.4171 - 208s/epoch - 115ms/step
Epoch 12/130
1813/1813 - 208s - loss: 124.4215 - mse: 81.9172 - val_loss: 231.3461 - val_mse: 177.3840 - 208s/epoch - 115ms/step
Epoch 13/130
1813/1813 - 209s - loss: 121.0553 - mse: 79.6488 - val_loss: 233.8736 - val_mse: 179.0067 - 209s/epoch - 115ms/step
Epoch 14/130
1813/1813 - 210s - loss: 118.0474 - mse: 77.6793 - val_loss: 229.0045 - val_mse: 175.8362 - 210s/epoch - 116ms/step
Epoch 15/130
1813/1813 - 212s - loss: 115.6248 - mse: 76.0733 - val_loss: 222.0146 - val_mse: 169.3506 - 212s/epoch - 117ms/step
Epoch 16/130
1813/1813 - 211s - loss: 113.8086 - mse: 74.8634 - val_loss: 236.5103 - val_mse: 182.1108 - 211s/epoch - 116ms/step
Epoch 17/130
1813/1813 - 209s - loss: 112.2991 - mse: 73.8687 - val_loss: 237.6510 - val_mse: 183.4337 - 209s/epoch - 115ms/step
Epoch 18/130
1813/1813 - 207s - loss: 111.1429 - mse: 73.0768 - val_loss: 225.2420 - val_mse: 173.4565 - 207s/epoch - 114ms/step
Epoch 19/130
1813/1813 - 209s - loss: 110.4482 - mse: 72.6236 - val_loss: 226.3741 - val_mse: 174.4131 - 209s/epoch - 115ms/step
Epoch 20/130
1813/1813 - 210s - loss: 110.1900 - mse: 72.4576 - val_loss: 226.3549 - val_mse: 174.3902 - 210s/epoch - 116ms/step
Epoch 21/130
1813/1813 - 209s - loss: 129.4420 - mse: 85.7716 - val_loss: 225.4606 - val_mse: 172.4784 - 209s/epoch - 115ms/step
Epoch 22/130
1813/1813 - 211s - loss: 126.1635 - mse: 83.5960 - val_loss: 234.9332 - val_mse: 181.5918 - 211s/epoch - 116ms/step
Epoch 23/130
1813/1813 - 209s - loss: 123.3188 - mse: 81.6693 - val_loss: 236.1611 - val_mse: 181.1728 - 209s/epoch - 115ms/step
Epoch 24/130
1813/1813 - 209s - loss: 120.5493 - mse: 79.8113 - val_loss: 250.4812 - val_mse: 195.4315 - 209s/epoch - 115ms/step
Epoch 25/130
1813/1813 - 209s - loss: 118.4465 - mse: 78.4013 - val_loss: 248.8815 - val_mse: 192.6835 - 209s/epoch - 115ms/step
Epoch 26/130
1813/1813 - 208s - loss: 116.1241 - mse: 76.8909 - val_loss: 221.3715 - val_mse: 169.4061 - 208s/epoch - 114ms/step
Epoch 27/130
1813/1813 - 207s - loss: 114.1093 - mse: 75.5681 - val_loss: 271.1044 - val_mse: 213.1560 - 207s/epoch - 114ms/step
Epoch 28/130
1813/1813 - 208s - loss: 112.1188 - mse: 74.2363 - val_loss: 259.9726 - val_mse: 203.0574 - 208s/epoch - 115ms/step
Epoch 29/130
1813/1813 - 208s - loss: 110.6153 - mse: 73.2523 - val_loss: 254.9733 - val_mse: 198.4745 - 208s/epoch - 115ms/step
Epoch 30/130
1813/1813 - 208s - loss: 108.9965 - mse: 72.2142 - val_loss: 259.5781 - val_mse: 203.6358 - 208s/epoch - 115ms/step
Epoch 31/130
1813/1813 - 209s - loss: 107.7083 - mse: 71.3746 - val_loss: 283.1126 - val_mse: 224.0894 - 209s/epoch - 115ms/step
Epoch 32/130
1813/1813 - 209s - loss: 106.3245 - mse: 70.4747 - val_loss: 189.7666 - val_mse: 142.6517 - 209s/epoch - 115ms/step
Epoch 33/130
